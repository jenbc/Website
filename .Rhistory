api_key <- "BPBQ9S5KC5kqjU5QfiwpzPSFU"
api_secret <- "XkD4m3LTebSiWIVtvnqFdQIGfFCjkLnqDHLSoLkZsIjFa4Hxr7"
access_token <- "832060427852972033-nthFWKgvQg5PVacKqouyUtSAupgMthe"
access_token_secret <- "DrVf0KlZDiAwbTeefTmzeLLtDn3D6UA2DXx6a2MBXBrix"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
1
skip_tweets = searchTwitter("Flynn", n = 1000)
# Transform Raw Twitter Data to Dataframe
skip_tweetsDF = twListToDF(skip_tweets)
## Transformation of Tweets to DocumentTermMatrix
sk = skip_tweetsDF$text
TextPreprocessing = lapply(sk, function(x) {
x = gsub('http\\S+\\s*', '', x) ## Remove URLs
x = gsub('\\b+RT', '', x) ## Remove RT
x = gsub('#\\S+', '', x) ## Remove Hashtags
x = gsub('@\\S+', '', x) ## Remove Mentions
x = gsub('[[:cntrl:]]', '', x) ## Remove Controls and special characters
x = gsub("\\d", '', x) ## Remove Controls and special characters
x = gsub('[[:punct:]]', '', x) ## Remove Punctuations
x = gsub("^[[:space:]]*","",x) ## Remove leading whitespaces
x = gsub("[[:space:]]*$","",x) ## Remove trailing whitespaces
})
# or as a vector
bd_list = as.vector(TextPreprocessing)
mycorpus <- Corpus(VectorSource(bd_list))
mycorpus = tm_map(mycorpus, content_transformer(function(x) iconv(x, to='UTF-8-MAC', sub='byte')))
### Transformer all characters to lower case
mycorpus = tm_map(mycorpus, content_transformer(tolower))
### Remove all Punctuation
mycorpus = tm_map(mycorpus, removePunctuation)
### Remove all Numbers
mycorpus = tm_map(mycorpus, removeNumbers)
### Remove Stopwords
mycorpus = tm_map(mycorpus, removeWords, stopwords('english'))
#### transform to Document Term Matrix
skip.dtm = DocumentTermMatrix(mycorpus)
rowTotals = apply(skip.dtm, 1, sum)
smtpmodel = skip.dtm[rowTotals>0, ]
smmodel_tweets = LDA(smtpmodel, 5)
terms(smmodel_tweets , 40)
terms(smmodel_tweets , 40)
skip_tweetsDF$text <- iconv(skip_tweetsDF$text, 'UTF-8', 'ASCII')
# Get Sentiment Analysis
skip_Sentiment = get_nrc_sentiment(skip_tweetsDF$text)
#### Visualization for Overall Sentiment for Skip
sentTotals = data.frame(colSums(skip_Sentiment))
names(sentTotals) = "count"
sentTotals = cbind("sentiment" = rownames(sentTotals), sentTotals)
rownames(sentTotals) = NULL
ggplot(data = sentTotals, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score for All Trump Tweets")
xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score for All Flynn Tweets")
sentTotals = data.frame(colSums(skip_Sentiment))
names(sentTotals) = "count"
sentTotals = cbind("sentiment" = rownames(sentTotals), sentTotals)
rownames(sentTotals) = NULL
ggplot(data = sentTotals, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score for All Flynn Tweets")
topic_col=topics(smmodel_tweets)
topic_col2=as.data.frame(topic_col)
mine=as.data.frame(date=index(skip_tweetsDF$created), coredata(skip_tweetsDF$created))
mine = as.matrix(mine)
mine2 = mine[-as.numeric(empty.rows)]
topic_col2$date = mine2
empty.rows <- skip.dtm[rowTotals == 0, ]$dimnames[1][[1]]
mycorpus <- mycorpus[-as.numeric(empty.rows)]
topic_col=topics(smmodel_tweets)
topic_col2=as.data.frame(topic_col)
mine=as.data.frame(date=index(skip_tweetsDF$created), coredata(skip_tweetsDF$created))
mine = as.matrix(mine)
mine2 = mine[-as.numeric(empty.rows)]
topic_col2$date = mine2
write.table(topic_col2, "Flynn.csv", sep=",", col.names=T)
library(streamR)
library(ROAuth)
library(RCurl)
install.packages("streamR")
library(streamR)
library(ROAuth)
library(RCurl)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "RrcgW1vwgOAV187IBKvq1HK0T"
consumerSecret <- "I9W1YCPQLBliJOyHzVdKDRgoQPnSJ4G0sSpp3W8jjAshU4NGqd"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "RrcgW1vwgOAV187IBKvq1HK0T"
consumerSecret <- "I9W1YCPQLBliJOyHzVdKDRgoQPnSJ4G0sSpp3W8jjAshU4NGqd"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "ODlSvy4KWRcwM08ZXJHsOgtoa"
consumerSecret <- "mgdLlqNQ8bwkBM6e0CZFA54AyXz5p06eFw7FcvdC8RPeMqT7Bj"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
library("RCurl", lib.loc="~/R/win-library/3.3")
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
library("ROAuth", lib.loc="~/R/win-library/3.3")
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "ODlSvy4KWRcwM08ZXJHsOgtoa"
consumerSecret <- "mgdLlqNQ8bwkBM6e0CZFA54AyXz5p06eFw7FcvdC8RPeMqT7Bj"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
library("twitteR", lib.loc="~/R/win-library/3.3")
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
library("twitteR", lib.loc="~/R/win-library/3.3")
library(streamR)
library(ROAuth)
library(RCurl)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "4tnE4DKOr8hp8PbIpqbdplsuT"
consumerSecret <- "qgqoC7yG2h39K2RVvgTeaMyFuQoWc1ODenVNc53DoLn3BHZA59"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
1
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 300,
oauth = my_oauth)
## You can obtain your own at dev.twitter.com
library(streamR)
library(ROAuth)
library(RCurl)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "4tnE4DKOr8hp8PbIpqbdplsuT"
consumerSecret <- "qgqoC7yG2h39K2RVvgTeaMyFuQoWc1ODenVNc53DoLn3BHZA59"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
## not "http" make sure "https"
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "4tnE4DKOr8hp8PbIpqbdplsuT"
consumerSecret <- "qgqoC7yG2h39K2RVvgTeaMyFuQoWc1ODenVNc53DoLn3BHZA59"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
## not "http" make sure "https"
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "ZKFlRToB9of8SDtO4Fp8zwrj2"
consumerSecret <- "Lq50dUgPSznhCp7bzAVJWe8hKWjRKSLYBXmLpMUMMvkruql2hM"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
## not "http" make sure "https"
1
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "ZKFlRToB9of8SDtO4Fp8zwrj2"
consumerSecret <- "Lq50dUgPSznhCp7bzAVJWe8hKWjRKSLYBXmLpMUMMvkruql2hM"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
## not "http" make sure "https"
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "W5t2hOHQ38zSlA2YP3syeHlrs"
consumerSecret <- "irtY9JC4pPNGVDD5f5BtAXApYdA8zLORzpG5O9KoKg1dgI8sdN"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
## not "http" make sure "htt
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "UUaoNTE1Ffph1ohts5UeZ0An0"
consumerSecret <- "ae4MX2dpXwZhSnpTBgqBVLqQTXAh1BIt3d9s1hSc6U9eH00Uxw"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
## capture tweets sent from New York City in Spanish only, and saving as an object in memory
tweets=filterStream(file.name="Help", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=300, oauth=my_oauth)
## capture tweets sent from New York City in Spanish only, and saving as an object in memory
tweets=filterStream(file.name="Help", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=100, oauth=my_oauth)
## capture tweets sent from New York City in Spanish only, and saving as an object in memory
tweets=filterStream(file.name="Help", language="en", track="Biden",
locations=c(-74,40,-73,41), timeout=100, oauth=my_oauth)
tweets.df <- parseTweets("ny_english", simplify = TRUE)
tweets=filterStream(file.name="ny_english", language="en", track="Biden",
locations=c(-74,40,-73,41), timeout=100, oauth=my_oauth)
4900059
tweets=filterStream(file.name="ny_english", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=40, oauth=my_oauth)
tweets=filterStream(file.name="ny_english", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=15, oauth=my_oauth)
library(streamR)
library(ROAuth)
library(RCurl)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "UUaoNTE1Ffph1ohts5UeZ0An0"
consumerSecret <- "ae4MX2dpXwZhSnpTBgqBVLqQTXAh1BIt3d9s1hSc6U9eH00Uxw"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
tweets=filterStream(file.name="ny_english", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=120, oauth=my_oauth)
library("digest", lib.loc="~/R/win-library/3.3")
tweets=filterStream(file.name="ny_english", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=120, oauth=my_oauth)
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "UUaoNTE1Ffph1ohts5UeZ0An0"
consumerSecret <- "ae4MX2dpXwZhSnpTBgqBVLqQTXAh1BIt3d9s1hSc6U9eH00Uxw"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 20,
oauth = my_oauth)
tweets.df <- parseTweets("tweetsUS.json", verbose = FALSE)
filterStream("tweetsUS.json", locations = c(-125, 25, -66, 50), timeout = 30,
oauth = my_oauth)
tweets.df <- parseTweets("tweetsUS.json", verbose = FALSE)
tweets=filterStream(file.name="ny_english", language="en", track="trump",
locations=c(-74,40,-73,41), timeout=120, oauth=my_oauth)
## Parse tweets
requestURL <- "https://api.twitter.com/oauth/request_token"
accessURL <- "https://api.twitter.com/oauth/access_token"
authURL <- "https://api.twitter.com/oauth/authorize"
consumerKey <- "UUaoNTE1Ffph1ohts5UeZ0An0"
consumerSecret <- "ae4MX2dpXwZhSnpTBgqBVLqQTXAh1BIt3d9s1hSc6U9eH00Uxw"
my_oauth <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret, requestURL=requestURL,
accessURL=accessURL, authURL=authURL)
1
my_oauth$handshake(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl"))
tweets=filterStream(file.name="ny_english", language="en", track="fake news",
locations=c(-74,40,-73,41), timeout=120, oauth=my_oauth)
tweets = searchTwitter("Macron", n=3000, since = '2017-05-01', until = '2017-05-03')
## Packages for Social Network Analysis
library(igraph)
library(graphTweets)
### Scraping Twitter Data in R and Text Analysis
library(twitteR)
library(ROAuth)
library(httr)
library(plyr)
library(tm)
library(rpart)
library(rpart.plot)
library(zoo)
library(xts)
library(topicmodels)
## Required packages LDAvis (dplyr and tm)
library(topicmodels)
library(stringi)
library(LDAvis)
### Sentiment Analysis with Twitter Data
library(syuzhet)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
tweets = searchTwitter("Macron", n=3000, since = '2017-05-01', until = '2017-05-03')
api_key <- "zwrmdJxCBKUl4RJJvd3pugcPf"
api_secret <- "WnhihX4375YVStwtOWkgP8lQsiLnkX0xr0m2S12Eqj7Jyz2C20"
access_token <- "448407597-NapWwwNmUcka6Gz8xZm2B9UMZqFyGN72Bcil2dwi"
access_token_secret <- "Oh5Wni21QWFrpaBCGvct6wqG6BOpLZfFp403Q4etKgpUM"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
1
tweets = searchTwitter("Macron", n=3000, since = '2017-05-01', until = '2017-05-03')
tw_df <- twListToDF(tweets)
edges <- getEdges(data = tw_df, tweets = "text", source = "screenName", "retweetCount", str.length = 20)
nodes <- getNodes(edges, source = "source", target="target")
g <- graph.data.frame(edges, directed = TRUE, vertices = nodes)
write.graph(g, file="forgephi2.graphml", format="graphml")
library(igraph)
library(graphTweets)
### Scraping Twitter Data in R and Text Analysis
library(twitteR)
library(ROAuth)
library(httr)
library(plyr)
library(tm)
library(rpart)
library(rpart.plot)
library(zoo)
library(xts)
library(topicmodels)
## Required packages LDAvis (dplyr and tm)
library(topicmodels)
library(stringi)
library(LDAvis)
### Sentiment Analysis with Twitter Data
library(syuzhet)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
api_key <- "zwrmdJxCBKUl4RJJvd3pugcPf"
api_secret <- "WnhihX4375YVStwtOWkgP8lQsiLnkX0xr0m2S12Eqj7Jyz2C20"
access_token <- "448407597-NapWwwNmUcka6Gz8xZm2B9UMZqFyGN72Bcil2dwi"
access_token_secret <- "Oh5Wni21QWFrpaBCGvct6wqG6BOpLZfFp403Q4etKgpUM"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
1
tweets = searchTwitter("Comey", n=3000, since = '2017-06-05', until = '2017-06-07')
tw_df <- twListToDF(tweets)
edges <- getEdges(data = tw_df, tweets = "text", source = "screenName", "retweetCount", str.length = 20)
nodes <- getNodes(edges, source = "source", target="target")
g <- graph.data.frame(edges, directed = TRUE, vertices = nodes)
write.graph(g, file="forgephi3.graphml", format="graphml")
Gephidyn <- dynamise(tw_df, tweets = "text", source = "screenName", start.stamp = "created", write = TRUE, open = TRUE)
write.graph(Gephidyn, file="Comey.graphml", format="graphml")
sk = tw_df$text
TextPreprocessing = lapply(sk, function(x) {
x = gsub('http\\S+\\s*', '', x) ## Remove URLs
x = gsub('\\b+RT', '', x) ## Remove RT
x = gsub('#\\S+', '', x) ## Remove Hashtags
x = gsub('@\\S+', '', x) ## Remove Mentions
x = gsub('[[:cntrl:]]', '', x) ## Remove Controls and special characters
x = gsub("\\d", '', x) ## Remove Controls and special characters
x = gsub('[[:punct:]]', '', x) ## Remove Punctuations
x = gsub("^[[:space:]]*","",x) ## Remove leading whitespaces
x = gsub("[[:space:]]*$","",x) ## Remove trailing whitespaces
})
# or as a vector
bd_list = as.vector(TextPreprocessing)
mycorpus <- Corpus(VectorSource(bd_list))
mycorpus = tm_map(mycorpus, content_transformer(function(x) iconv(x, to='UTF-8', sub='byte')))
### Transformer all characters to lower case
mycorpus = tm_map(mycorpus, content_transformer(tolower))
### Remove all Punctuation
mycorpus = tm_map(mycorpus, removePunctuation)
### Remove all Numbers
mycorpus = tm_map(mycorpus, removeNumbers)
### Remove Stopwords
mycorpus = tm_map(mycorpus, removeWords, stopwords('english'))
#### transform to Document Term Matrix
skip.dtm = DocumentTermMatrix(mycorpus)
rowTotals = apply(skip.dtm, 1, sum)
smtpmodel = skip.dtm[rowTotals>0, ]
smmodel_tweets = LDA(smtpmodel, 5)
terms(smmodel_tweets , 40)
rowTotals = apply(skip.dtm, 1, sum)
smtpmodel = skip.dtm[rowTotals>0, ]
smmodel_tweets = LDA(smtpmodel, 5)
terms(smmodel_tweets , 40)
topic_col=topics(smmodel_tweets)
topic_col2=as.data.frame(topic_col)
### Scraping Twitter Data in R and Text Analysis
library(streamR)
library(ROAuth)
library(RCurl)
## Packages for Social Network Analysis
library(igraph)
library(graphTweets)
### Scraping Twitter Data in R and Text Analysis
library(twitteR)
library(ROAuth)
library(httr)
library(plyr)
library(tm)
library(rpart)
library(rpart.plot)
library(zoo)
library(xts)
library(topicmodels)
## Required packages LDAvis (dplyr and tm)
library(topicmodels)
library(stringi)
library(LDAvis)
### Sentiment Analysis with Twitter Data
library(syuzhet)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(twitteR)
library(ROAuth)
library(httr)
library(plyr)
library(tm)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(LDAvis)
### Sentiment Analysis with Twitter Data
library(syuzhet)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
#word cloud and others
library(wordcloud)
library(zoo)
Macron_tweets = searchTwitter("Comey", n=3000, lang = "en", since = '2017-06-05', until = '2017-06-07')
# Transform Raw Twitter Data to Dataframe
Macron_tweetsDF = twListToDF(Macron_tweets)
## Transformation of Tweets to DocumentTermMatrix
Mc = Macron_tweetsDF$text
TextPreprocessing = lapply(Mc, function(x) {
x = gsub('http\\S+\\s*', '', x) ## Remove URLs
x = gsub('\\b+RT', '', x) ## Remove RT
x = gsub('#\\S+', '', x) ## Remove Hashtags
x = gsub('@\\S+', '', x) ## Remove Mentions
x = gsub('[[:cntrl:]]', '', x) ## Remove Controls and special characters
x = gsub("\\d", '', x) ## Remove Controls and special characters
x = gsub('[[:punct:]]', '', x) ## Remove Punctuations
x = gsub("^[[:space:]]*","",x) ## Remove leading whitespaces
x = gsub("[[:space:]]*$","",x) ## Remove trailing whitespaces
})
# or as a vector
bd_list = as.vector(TextPreprocessing)
mycorpus <- Corpus(VectorSource(bd_list))
mycorpus = tm_map(mycorpus, content_transformer(function(x) iconv(x, to='UTF-8', sub='byte')))
### Transformer all characters to lower case
mycorpus = tm_map(mycorpus, content_transformer(tolower))
### Remove all Punctuation
mycorpus = tm_map(mycorpus, removePunctuation)
### Remove all Numbers
mycorpus = tm_map(mycorpus, removeNumbers)
### Remove Stopwords
mycorpus = tm_map(mycorpus, removeWords, stopwords('english'))
#### transform to Document Term Matrix
macron.dtm = DocumentTermMatrix(mycorpus)
rowTotals = apply(macron.dtm, 1, sum)
smtpmodel = macron.dtm[rowTotals>0, ]
smmodel_tweets = LDA(smtpmodel, 5)
terms(smmodel_tweets , 40)
Macron_tweetsDF$text <- iconv(Macron_tweetsDF$text, 'UTF-8', 'ASCII')
# Get Sentiment Analysis
Macron_Sentiment = get_nrc_sentiment(Macron_tweetsDF$text)
#### Visualization for Overall Sentiment for Skip
sentTotals = data.frame(colSums(Macron_Sentiment))
names(sentTotals) = "count"
sentTotals = cbind("sentiment" = rownames(sentTotals), sentTotals)
rownames(sentTotals) = NULL
ggplot(data = sentTotals, aes(x = sentiment, y = count)) +
geom_bar(aes(fill = sentiment), stat = "identity") +
theme(legend.position = "none") +
xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score for All Macron Tweets Between May 4 and May 6")
install.packages("Lahman")
install.packages("sqldf")
library("Lahman", lib.loc="~/R/win-library/3.3")
library(Lahman)
library(Lahman)
library(sqldf)
batting
Batting
colnames(Batting)
#write a query and variable for query
query<-"SELECT playerID, yearID, teamID, HR From Batting"
query<-"SELECT playerID,yearID,teamID,HR From Batting"
#write a query and variable for query
query<-"SELECT playerID,yearID,teamID,HR From Batting"
sqldf(query)
query<-"SELECT playerID,yearID,teamID,HR From Batting
Where teamID='NYA'"
sqldf(query)
query<-"SELECT playerID,yearID,teamID,HR From Batting
Where teamID='NYA' and yearID=1927"
sqldf(query)
setwd()
setwd(desktop)
setwd("~/erie/Senior")
setwd("~/erie/Senior/Website")
setwd("C:/Users/jenbli/Desktop/Website")
